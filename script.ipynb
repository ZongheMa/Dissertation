{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/1k/27mkp8bj3ps60c3nmr7rbqzh0000gn/T/ipykernel_14963/1895528008.py:1: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import IPython.display as display\n",
    "import copy\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T20:51:03.985012Z",
     "start_time": "2023-08-13T20:51:03.743305Z"
    }
   },
   "id": "1747391cd6880ed2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "def merge_csv_files(directory):\n",
    "    # Get a list of all the csv files\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty list to hold dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through csv files, read each into a dataframe, and append to the list\n",
    "    for file in csv_files:\n",
    "        # Extract date from filename, assuming the date is in format 'traffic_flow_YYYY_MM_DD'\n",
    "        date_str = file.split('.')[0].split('_')[-3:]  # This gives ['YYYY', 'MM', 'DD']\n",
    "        date = datetime.strptime('_'.join(date_str), '%Y_%m_%d').date()\n",
    "\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "\n",
    "        # Add date as a new column\n",
    "        df['date'] = date.strftime('%m/%d/%y')\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list into one dataframe\n",
    "    merged_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    # Return the merged dataframe\n",
    "    return merged_df\n",
    "\n",
    "traffic_flows = merge_csv_files(\n",
    "    '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]Traffic flow')\n",
    "road_network = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp'\n",
    "\n",
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()\n",
    "\n",
    "lsoa = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/london_LSOA/london_LSOA.shp'\n",
    "\n",
    "inoutter = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/lp-consultation-oct-2009-inner-outer-london-shp/lp-consultation-oct-2009-inner-outer-london.shp'\n",
    "# tube_line = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_lines.json'\n",
    "# tube_station = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_stations.json'\n",
    "\n",
    "inoutter = gpd.read_file(inoutter)\n",
    "inoutter.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "# tube_station = gpd.read_file(tube_station)\n",
    "# tube_station.to_crs(epsg=27700, inplace=True)\n",
    "# tube_station = gpd.sjoin(tube_station, inoutter, op='within')\n",
    "\n",
    "# tube_line = gpd.read_file(tube_line)\n",
    "# tube_line.to_crs(epsg=27700, inplace=True)\n",
    "# tube_line = gpd.sjoin(tube_line, inoutter, op='within')\n",
    "\n",
    "lsoa = gpd.read_file(lsoa, crs={'init': 'epsg:27700'})\n",
    "road_network = gpd.read_file(road_network, crs={'init': 'epsg:27700'})\n",
    "road_network.rename(columns={'NAME': 'boroughs'}, inplace=True)\n",
    "\n",
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()\n",
    "traffic_flows['total'] = traffic_flows['bus'] + traffic_flows['car'] + traffic_flows['cycle'] + traffic_flows[\n",
    "    'walks'] + traffic_flows['stationary']\n",
    "\n",
    "flows = pd.merge(\n",
    "    road_network[\n",
    "        ['toid', 'roadclassi', 'geometry', 'cycle_lane', 'bus_lane', 'boroughs']],\n",
    "    traffic_flows, left_on='toid', right_on='toid', how='left')\n",
    "flows.set_geometry('geometry', inplace=True)\n",
    "\n",
    "flows['classification'] = flows['roadclassi'].replace(\n",
    "    {'Unknown': 'Local Road', 'Not Classified': 'Local Road', 'Unclassified': 'Local Road',\n",
    "     'Classified Unnumbered': 'Local Road', 'A Road': 'Strategic Road', 'B Road': 'Strategic Road'})\n",
    "flows.drop(columns=['roadclassi'], inplace=True)\n",
    "stage_date = ['03/01/22', '02/22/22', '03/08/22']\n",
    "flows = flows.loc[flows['date'].isin(stage_date)]\n",
    "# label the regional level\n",
    "flows = gpd.sjoin(flows, inoutter, how='inner', predicate='within')\n",
    "flows = flows.drop(columns=['index_right', 'Source', 'Area_Ha', 'Shape_Leng', 'Shape_Area'])\n",
    "flows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "merged = flows\n",
    "\n",
    "# convert the dataframe\n",
    "flows = pd.melt(flows,\n",
    "                id_vars=['toid', 'classification', 'geometry', 'date', 'Boundary', 'cycle_lane', 'bus_lane',\n",
    "                         'boroughs'],\n",
    "                var_name='mode', value_name='flow')\n",
    "\n",
    "flows = pd.pivot_table(flows,\n",
    "                       index=['toid'],\n",
    "                       columns='date',\n",
    "                       values='flow',\n",
    "                       aggfunc='first').reset_index()\n",
    "\n",
    "flows['classification'] = flows['toid'].map('classification', 'geometry', 'Boundary', 'mode', 'cycle_lane', 'bus_lane',\n",
    "                                            'boroughs')\n",
    "\n",
    "flows.drop(columns=['date'], inplace=True)\n",
    "flows = flows.groupby(\n",
    "    ['toid', 'mode', 'classification', 'geometry', 'Boundary', 'cycle_lane', 'bus_lane', 'boroughs'],\n",
    "    as_index=False).agg(\n",
    "    {'03/01/22': 'first', '02/22/22': 'first', '03/08/22': 'first'})\n",
    "# Calculate the impact and recovery flows for one strike\n",
    "flows['impact_flow'] = flows['03/01/22'] - flows['02/22/22']\n",
    "flows['recovery_flow'] = flows['03/08/22'] - flows['03/01/22']\n",
    "\n",
    "# Calculate impact rate while avoiding division by zero\n",
    "flows['impact_rate'] = flows.apply(\n",
    "    lambda row: round(row['impact_flow'] / row['02/22/22'], 4) if row['02/22/22'] != 0 else 0, axis=1)\n",
    "# Calculate recovery rate while avoiding division by zero\n",
    "flows['recovery_rate'] = flows.apply(\n",
    "    lambda row: round(row['recovery_flow'] / row['03/01/22'], 4) if row['03/01/22'] != 0 else 0, axis=1)\n",
    "\n",
    "All = flows.copy()\n",
    "All"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-13T20:54:40.209341Z",
     "start_time": "2023-08-13T20:51:15.737721Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "55dd9fb9f192d24f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
