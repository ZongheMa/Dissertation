{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:10:20.316212Z",
     "start_time": "2023-07-23T19:10:19.473258Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.11.1-CAPI-1.17.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/var/folders/1k/27mkp8bj3ps60c3nmr7rbqzh0000gn/T/ipykernel_15730/4125638018.py:1: DeprecationWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas still uses PyGEOS by default. However, starting with version 0.14, the default will switch to Shapely. To force to use Shapely 2.0 now, you can either uninstall PyGEOS or set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In the next release, GeoPandas will switch to using Shapely by default, even if PyGEOS is installed. If you only have PyGEOS installed to get speed-ups, this switch should be smooth. However, if you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gpd\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def merge_csv_files(directory):\n",
    "    # Get a list of all the csv files\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty list to hold dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through csv files, read each into a dataframe, and append to the list\n",
    "    for file in csv_files:\n",
    "        # Extract date from filename, assuming the date is in format 'traffic_flow_YYYY_MM_DD'\n",
    "        date_str = file.split('.')[0].split('_')[-3:]  # This gives ['YYYY', 'MM', 'DD']\n",
    "        date = datetime.strptime('_'.join(date_str), '%Y_%m_%d').date()\n",
    "\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "\n",
    "        # Add date as a new column\n",
    "        df['date'] = date.strftime('%m/%d/%y')\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list into one dataframe\n",
    "    merged_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    # Return the merged dataframe\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:10:20.322024Z",
     "start_time": "2023-07-23T19:10:20.317088Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "traffic_flows = merge_csv_files(\n",
    "    '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]Traffic flow')\n",
    "road_network = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp'\n",
    "\n",
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()\n",
    "\n",
    "road_network = gpd.read_file(road_network, crs={'init': 'epsg:27700'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:11:03.881177Z",
     "start_time": "2023-07-23T19:10:20.324063Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3445: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "lsoa = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/london_LSOA/london_LSOA.shp'\n",
    "road_network = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp'\n",
    "inoutter = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/lp-consultation-oct-2009-inner-outer-london-shp/lp-consultation-oct-2009-inner-outer-london.shp'\n",
    "tube_line = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_lines.json'\n",
    "tube_station = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_stations.json'\n",
    "\n",
    "inoutter = gpd.read_file(inoutter)\n",
    "inoutter.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "tube_station = gpd.read_file(tube_station)\n",
    "tube_station.to_crs(epsg=27700, inplace=True)\n",
    "tube_station = gpd.sjoin(tube_station, inoutter, op='within')\n",
    "\n",
    "tube_line = gpd.read_file(tube_line)\n",
    "tube_line.to_crs(epsg=27700, inplace=True)\n",
    "tube_line = gpd.sjoin(tube_line, inoutter, op='within')\n",
    "\n",
    "lsoa = gpd.read_file(lsoa, crs={'init': 'epsg:27700'})\n",
    "road_network = gpd.read_file(road_network, crs={'init': 'epsg:27700'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:11:47.419864Z",
     "start_time": "2023-07-23T19:11:05.384463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:11:50.934530Z",
     "start_time": "2023-07-23T19:11:47.418378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "flows = pd.merge(\n",
    "    road_network[['toid', 'roadclassi', 'routehiera', 'geometry',\n",
    "                  'directiona', 'length', 'roadwidthm', 'elevationg'\n",
    "                  ]],\n",
    "    traffic_flows, left_on='toid', right_on='toid', how='right')\n",
    "\n",
    "# Perform the aggregation to road network level\n",
    "cycle = traffic_flows.pivot(index='toid', columns='date', values='cycle')\n",
    "\n",
    "cycle = pd.merge(road_network[['toid', 'roadclassi', 'routehiera', 'geometry',\n",
    "                               'directiona', 'length', 'roadwidthm', 'elevationg']],\n",
    "                 cycle,\n",
    "                 left_on='toid', right_on='toid', how='left').reset_index()\n",
    "# obtain the date columns\n",
    "date_columns = cycle.columns[cycle.columns.str.contains('/')]\n",
    "\n",
    "# Calculate the difference between each date column\n",
    "for i, col in enumerate(date_columns[1:], 1):\n",
    "    diff_col_name = f'diff_{col}'\n",
    "    cycle[diff_col_name] = cycle[date_columns[i]] - cycle[date_columns[i - 1]]\n",
    "\n",
    "# Calculate the sum and the difference weekly\n",
    "week_sums = cycle[date_columns].rolling(window=7, axis=1).sum().iloc[:, 6::7]\n",
    "week_sums.rename(columns={col: f'sum_week_{i}' for i, col in enumerate(week_sums.columns, 1)}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:12:12.001159Z",
     "start_time": "2023-07-23T19:11:50.941125Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cycle = pd.concat([cycle, week_sums], axis=1)\n",
    "cycle['diff_week_1&2'] = cycle['sum_week_2'] - cycle['sum_week_1']\n",
    "cycle['diff_week_2&3'] = cycle['sum_week_3'] - cycle['sum_week_2']\n",
    "\n",
    "# re classify the road class\n",
    "# print(cycle['roadclassi'].unique())\n",
    "# ['Unknown' 'Not Classified' 'Unclassified' 'B Road' 'A Road' 'Classified Unnumbered' 'Motorway']\n",
    "# print(cycle['directiona'].unique())\n",
    "# ['bothDirections' 'inOppositeDirection' 'inDirection']\n",
    "\n",
    "cycle['classification'] = cycle['roadclassi'].replace(\n",
    "    {'Unknown': 'Other', 'Not Classified': 'Other', 'Unclassified': 'Other', 'Classified Unnumbered': 'Other'})\n",
    "cycle.drop(columns=['roadclassi', 'index', 'routehiera'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:12:12.317952Z",
     "start_time": "2023-07-23T19:12:12.002101Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "flows_gdf = cycle"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:12:12.321423Z",
     "start_time": "2023-07-23T19:12:12.318586Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 创建一个空的无向图\n",
    "graph = nx.Graph()\n",
    "\n",
    "# 遍历 'flows' 数据，添加节点和边\n",
    "for index, row in flows_gdf.iterrows():\n",
    "    from_node = row['geometry'].coords[0]  # 路的起点\n",
    "    to_node = row['geometry'].coords[-1]  # 路的终点\n",
    "    flow = row['diff_03/01/22']  # Link 的权重，即 Flows\n",
    "    direction = row['directiona']  # Flow direction\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    graph.add_node(from_node, pos=from_node)  # Use 'from_node' as the node position\n",
    "    graph.add_node(to_node, pos=to_node)  # Use 'to_node' as the node position\n",
    "    # Add edges to the graph based on the direction\n",
    "    if direction == 'bothDirections':\n",
    "        # If the road is bidirectional, flows are split equally in both directions\n",
    "        graph.add_edge(from_node, to_node, weight=flow / 2,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "        graph.add_edge(to_node, from_node, weight=flow / 2,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "    elif direction == 'inOppositeDirection':\n",
    "        # If the road is in the opposite direction, flows are from the ending point to the starting point\n",
    "        graph.add_edge(to_node, from_node, weight=flow,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "    elif direction == 'inDirection':\n",
    "        # If the road is in the same direction, flows are from the starting point to the ending point\n",
    "        graph.add_edge(from_node, to_node, weight=flow,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T19:12:41.190204Z",
     "start_time": "2023-07-23T19:12:12.422462Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort edges based on their weight (flow) in descending order\n",
    "sorted_edges = sorted(graph.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)\n",
    "\n",
    "# Take the top 10% of edges with the highest flow\n",
    "top_10_edges = sorted_edges[:int(len(sorted_edges) * 0.1)]\n",
    "\n",
    "# Convert the edge tuples to a list of tuples containing only node names\n",
    "top_10_edges_nodes = [(u, v) for u, v, _ in top_10_edges]\n",
    "\n",
    "# Specify the desired 'classification' attribute values to display\n",
    "desired_classifications = ['Motorway', 'A Road', 'B Road', 'Other']\n",
    "\n",
    "\n",
    "# Create a subgraph containing all edges\n",
    "subgraph_all = graph.edge_subgraph(top_10_edges_nodes)\n",
    "\n",
    "# Get the positions of nodes using the 'pos' attribute for the subgraph containing all edges\n",
    "node_positions_all = nx.get_node_attributes(subgraph_all, 'pos')\n",
    "\n",
    "# Add a subplot for the fourth plot to show all road classifications\n",
    "fig, ax1 = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Loop through all edges in the subgraph containing all edges\n",
    "for u, v, data in subgraph_all.edges(data=True):\n",
    "    classification = data['classification']\n",
    "    # Set different colors based on the 'classification' attribute\n",
    "    edge_color = 'skyblue' if classification == 'Motorway' else 'green' if classification == 'A Road' else 'orange' if classification == 'B Road' else 'gray'\n",
    "    # Draw each edge with the corresponding color\n",
    "    nx.draw_networkx_edges(subgraph_all, pos=node_positions_all, edgelist=[(u, v)], edge_color=edge_color, width=2,\n",
    "                           alpha=0.7, ax=ax1)\n",
    "\n",
    "# Set the graph title and axis visibility for the fourth plot\n",
    "ax1.set_title('All Road Classifications')\n",
    "ax1.axis('off')\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-07-23T19:12:41.209120Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new figure and axis for the sub-plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15), dpi=600)\n",
    "\n",
    "# Loop through each desired classification and plot the corresponding subgraph\n",
    "for i, desired_classification in enumerate(desired_classifications):\n",
    "    # Create a subgraph containing only the top 10% edges with the specified 'classification'\n",
    "    subgraph = graph.edge_subgraph(\n",
    "        [(u, v) for u, v in top_10_edges_nodes if graph[u][v]['classification'] == desired_classification])\n",
    "\n",
    "    # Get the positions of nodes using the 'pos' attribute\n",
    "    node_positions = nx.get_node_attributes(subgraph, 'pos')\n",
    "\n",
    "    # Add a subplot for each desired classification\n",
    "    ax2 = axs[i // 2, i % 2]\n",
    "\n",
    "    # plot the background map\n",
    "    inoutter.boundary.plot(color='gray', ax=ax2, linewidth=2)\n",
    "\n",
    "    tube_line['geometry'] = tube_line.geometry.buffer(500)\n",
    "    tube_line.plot(color='gainsboro', ax=ax2, legend=True)\n",
    "    tube_station.plot(color='green', ax=ax2, legend=True)\n",
    "\n",
    "    try:\n",
    "        # Draw edges\n",
    "        nx.draw_networkx_edges(subgraph, pos=node_positions, width=2, edge_color='skyblue', ax=ax2)\n",
    "\n",
    "        # Set the graph title and axis visibility\n",
    "        ax1.set_title(f'Top 10% Edges with Highest Flow (Classification: {desired_classification})')\n",
    "        ax1.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for the classification '{desired_classification}': {e}\")\n",
    "\n",
    "# Adjust the layout to avoid overlapping plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
