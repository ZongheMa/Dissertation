{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-23T17:04:58.003228Z",
     "start_time": "2023-07-23T17:04:56.899491Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_compat.py:124: UserWarning: The Shapely GEOS version (3.9.1-CAPI-1.14.2) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyproj' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgpd\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnetworkx\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnx\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m options  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeoseries\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GeoSeries  \u001B[38;5;66;03m# noqa\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeodataframe\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GeoDataFrame  \u001B[38;5;66;03m# noqa\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_config.py:109\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcompat\u001B[39;00m\n\u001B[1;32m    104\u001B[0m     compat\u001B[38;5;241m.\u001B[39mset_use_pygeos(value)\n\u001B[1;32m    107\u001B[0m use_pygeos \u001B[38;5;241m=\u001B[39m Option(\n\u001B[1;32m    108\u001B[0m     key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_pygeos\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m--> 109\u001B[0m     default_value\u001B[38;5;241m=\u001B[39m\u001B[43m_default_use_pygeos\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    110\u001B[0m     doc\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    111\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWhether to use PyGEOS to speed up spatial operations. The default is True \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    112\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif PyGEOS is installed, and follows the USE_PYGEOS environment variable \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    113\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif set.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    114\u001B[0m     ),\n\u001B[1;32m    115\u001B[0m     validator\u001B[38;5;241m=\u001B[39m_validate_bool,\n\u001B[1;32m    116\u001B[0m     callback\u001B[38;5;241m=\u001B[39m_callback_use_pygeos,\n\u001B[1;32m    117\u001B[0m )\n\u001B[1;32m    120\u001B[0m options \u001B[38;5;241m=\u001B[39m Options({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay_precision\u001B[39m\u001B[38;5;124m\"\u001B[39m: display_precision, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_pygeos\u001B[39m\u001B[38;5;124m\"\u001B[39m: use_pygeos})\n",
      "File \u001B[0;32m/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_config.py:95\u001B[0m, in \u001B[0;36m_default_use_pygeos\u001B[0;34m()\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_default_use_pygeos\u001B[39m():\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgeopandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_compat\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mcompat\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m compat\u001B[38;5;241m.\u001B[39mUSE_PYGEOS\n",
      "File \u001B[0;32m/opt/anaconda3/envs/geospatial/lib/python3.8/site-packages/geopandas/_compat.py:262\u001B[0m\n\u001B[1;32m    255\u001B[0m     HAS_RTREE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;66;03m# -----------------------------------------------------------------------------\u001B[39;00m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;66;03m# pyproj compat\u001B[39;00m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;66;03m# -----------------------------------------------------------------------------\u001B[39;00m\n\u001B[0;32m--> 262\u001B[0m PYPROJ_GE_31 \u001B[38;5;241m=\u001B[39m Version(\u001B[43mpyproj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__version__\u001B[49m) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m Version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    263\u001B[0m PYPROJ_GE_32 \u001B[38;5;241m=\u001B[39m Version(pyproj\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m Version(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m3.2\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'pyproj' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def merge_csv_files(directory):\n",
    "    # Get a list of all the csv files\n",
    "    csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "    # Initialize an empty list to hold dataframes\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through csv files, read each into a dataframe, and append to the list\n",
    "    for file in csv_files:\n",
    "        # Extract date from filename, assuming the date is in format 'traffic_flow_YYYY_MM_DD'\n",
    "        date_str = file.split('.')[0].split('_')[-3:]  # This gives ['YYYY', 'MM', 'DD']\n",
    "        date = datetime.strptime('_'.join(date_str), '%Y_%m_%d').date()\n",
    "\n",
    "        df = pd.read_csv(os.path.join(directory, file))\n",
    "\n",
    "        # Add date as a new column\n",
    "        df['date'] = date.strftime('%m/%d/%y')\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Concatenate all dataframes in the list into one dataframe\n",
    "    merged_df = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    # Return the merged dataframe\n",
    "    return merged_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T17:05:01.460137Z",
     "start_time": "2023-07-23T17:05:01.456973Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m traffic_flows \u001B[38;5;241m=\u001B[39m \u001B[43mmerge_csv_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]Traffic flow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m road_network \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# clean the traffic flow data\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[2], line 3\u001B[0m, in \u001B[0;36mmerge_csv_files\u001B[0;34m(directory)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmerge_csv_files\u001B[39m(directory):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;66;03m# Get a list of all the csv files\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m     csv_files \u001B[38;5;241m=\u001B[39m [f \u001B[38;5;28;01mfor\u001B[39;00m f \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mlistdir(directory) \u001B[38;5;28;01mif\u001B[39;00m f\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)]\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Initialize an empty list to hold dataframes\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     dfs \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "traffic_flows = merge_csv_files(\n",
    "    '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]Traffic flow')\n",
    "road_network = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp'\n",
    "\n",
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()\n",
    "\n",
    "road_network = gpd.read_file(road_network, crs={'init': 'epsg:27700'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T17:05:03.040350Z",
     "start_time": "2023-07-23T17:05:03.038444Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lsoa = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/london_LSOA/london_LSOA.shp'\n",
    "road_network = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/[XH]road_network/road_network.shp'\n",
    "inoutter = '/Users/zonghe/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Zonghe Ma/Raw data/London administrative boundaries/lp-consultation-oct-2009-inner-outer-london-shp/lp-consultation-oct-2009-inner-outer-london.shp'\n",
    "tube_line = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_lines.json'\n",
    "tube_station = 'https://raw.githubusercontent.com/oobrien/vis/master/tubecreature/data/tfl_stations.json'\n",
    "\n",
    "inoutter = gpd.read_file(inoutter)\n",
    "inoutter.to_crs(epsg=27700, inplace=True)\n",
    "\n",
    "tube_station = gpd.read_file(tube_station)\n",
    "tube_station.to_crs(epsg=27700, inplace=True)\n",
    "tube_station = gpd.sjoin(tube_station, inoutter, op='within')\n",
    "\n",
    "tube_line = gpd.read_file(tube_line)\n",
    "tube_line.to_crs(epsg=27700, inplace=True)\n",
    "tube_line = gpd.sjoin(tube_line, inoutter, op='within')\n",
    "\n",
    "lsoa = gpd.read_file(lsoa, crs={'init': 'epsg:27700'})\n",
    "road_network = gpd.read_file(road_network, crs={'init': 'epsg:27700'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clean the traffic flow data\n",
    "traffic_flows = traffic_flows.drop_duplicates(['toid', 'date'])\n",
    "traffic_flows = traffic_flows.groupby(['toid', 'date']).agg(\n",
    "    {'bus': 'sum', 'car': 'sum', 'cycle': 'sum', 'walks': 'sum', 'stationary': 'sum'}).reset_index()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flows = pd.merge(\n",
    "    road_network[['toid', 'roadclassi', 'routehiera', 'geometry',\n",
    "                  'directiona', 'length', 'roadwidthm', 'elevationg'\n",
    "                  ]],\n",
    "    traffic_flows, left_on='toid', right_on='toid', how='right')\n",
    "\n",
    "# Perform the aggregation to road network level\n",
    "cycle = traffic_flows.pivot(index='toid', columns='date', values='cycle')\n",
    "\n",
    "cycle = pd.merge(road_network[['toid', 'roadclassi', 'routehiera', 'geometry',\n",
    "                               'directiona', 'length', 'roadwidthm', 'elevationg']],\n",
    "                 cycle,\n",
    "                 left_on='toid', right_on='toid', how='left').reset_index()\n",
    "# obtain the date columns\n",
    "date_columns = cycle.columns[cycle.columns.str.contains('/')]\n",
    "\n",
    "# Calculate the difference between each date column\n",
    "for i, col in enumerate(date_columns[1:], 1):\n",
    "    diff_col_name = f'diff_{col}'\n",
    "    cycle[diff_col_name] = cycle[date_columns[i]] - cycle[date_columns[i - 1]]\n",
    "\n",
    "# Calculate the sum and the difference weekly\n",
    "week_sums = cycle[date_columns].rolling(window=7, axis=1).sum().iloc[:, 6::7]\n",
    "week_sums.rename(columns={col: f'sum_week_{i}' for i, col in enumerate(week_sums.columns, 1)}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cycle = pd.concat([cycle, week_sums], axis=1)\n",
    "cycle['diff_week_1&2'] = cycle['sum_week_2'] - cycle['sum_week_1']\n",
    "cycle['diff_week_2&3'] = cycle['sum_week_3'] - cycle['sum_week_2']\n",
    "\n",
    "# re classify the road class\n",
    "# print(cycle['roadclassi'].unique())\n",
    "# ['Unknown' 'Not Classified' 'Unclassified' 'B Road' 'A Road' 'Classified Unnumbered' 'Motorway']\n",
    "# print(cycle['directiona'].unique())\n",
    "# ['bothDirections' 'inOppositeDirection' 'inDirection']\n",
    "\n",
    "cycle['classification'] = cycle['roadclassi'].replace(\n",
    "    {'Unknown': 'Other', 'Not Classified': 'Other', 'Unclassified': 'Other', 'Classified Unnumbered': 'Other'})\n",
    "cycle.drop(columns=['roadclassi', 'index', 'routehiera'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "flows_gdf = cycle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建一个空的无向图\n",
    "graph = nx.Graph()\n",
    "\n",
    "# 遍历 'flows' 数据，添加节点和边\n",
    "for index, row in flows_gdf.iterrows():\n",
    "    from_node = row['geometry'].coords[0]  # 路的起点\n",
    "    to_node = row['geometry'].coords[-1]  # 路的终点\n",
    "    flow = row['diff_03/01/22']  # Link 的权重，即 Flows\n",
    "    direction = row['directiona']  # Flow direction\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    graph.add_node(from_node, pos=from_node)  # Use 'from_node' as the node position\n",
    "    graph.add_node(to_node, pos=to_node)  # Use 'to_node' as the node position\n",
    "    # Add edges to the graph based on the direction\n",
    "    if direction == 'bothDirections':\n",
    "        # If the road is bidirectional, flows are split equally in both directions\n",
    "        graph.add_edge(from_node, to_node, weight=flow / 2,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "        graph.add_edge(to_node, from_node, weight=flow / 2,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "    elif direction == 'inOppositeDirection':\n",
    "        # If the road is in the opposite direction, flows are from the ending point to the starting point\n",
    "        graph.add_edge(to_node, from_node, weight=flow,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n",
    "    elif direction == 'inDirection':\n",
    "        # If the road is in the same direction, flows are from the starting point to the ending point\n",
    "        graph.add_edge(from_node, to_node, weight=flow,\n",
    "                       toid=row['toid'], classification=row['classification'], geometry=row['geometry'])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort edges based on their weight (flow) in descending order\n",
    "sorted_edges = sorted(graph.edges(data=True), key=lambda x: x[2]['weight'], reverse=True)\n",
    "\n",
    "# Take the top 10% of edges with the highest flow\n",
    "top_10_edges = sorted_edges[:int(len(sorted_edges) * 0.1)]\n",
    "\n",
    "# Convert the edge tuples to a list of tuples containing only node names\n",
    "top_10_edges_nodes = [(u, v) for u, v, _ in top_10_edges]\n",
    "\n",
    "# Specify the desired 'classification' attribute values to display\n",
    "desired_classifications = ['Motorway', 'A Road', 'B Road', 'Other']\n",
    "\n",
    "\n",
    "# Create a subgraph containing all edges\n",
    "subgraph_all = graph.edge_subgraph(top_10_edges_nodes)\n",
    "\n",
    "# Get the positions of nodes using the 'pos' attribute for the subgraph containing all edges\n",
    "node_positions_all = nx.get_node_attributes(subgraph_all, 'pos')\n",
    "\n",
    "# Add a subplot for the fourth plot to show all road classifications\n",
    "fig, ax1 = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Loop through all edges in the subgraph containing all edges\n",
    "for u, v, data in subgraph_all.edges(data=True):\n",
    "    classification = data['classification']\n",
    "    # Set different colors based on the 'classification' attribute\n",
    "    edge_color = 'skyblue' if classification == 'Motorway' else 'green' if classification == 'A Road' else 'orange' if classification == 'B Road' else 'gray'\n",
    "    # Draw each edge with the corresponding color\n",
    "    nx.draw_networkx_edges(subgraph_all, pos=node_positions_all, edgelist=[(u, v)], edge_color=edge_color, width=2,\n",
    "                           alpha=0.7, ax=ax1)\n",
    "\n",
    "# Set the graph title and axis visibility for the fourth plot\n",
    "ax1.set_title('All Road Classifications')\n",
    "ax1.axis('off')\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new figure and axis for the sub-plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15), dpi=600)\n",
    "\n",
    "# Loop through each desired classification and plot the corresponding subgraph\n",
    "for i, desired_classification in enumerate(desired_classifications):\n",
    "    # Create a subgraph containing only the top 10% edges with the specified 'classification'\n",
    "    subgraph = graph.edge_subgraph(\n",
    "        [(u, v) for u, v in top_10_edges_nodes if graph[u][v]['classification'] == desired_classification])\n",
    "\n",
    "    # Get the positions of nodes using the 'pos' attribute\n",
    "    node_positions = nx.get_node_attributes(subgraph, 'pos')\n",
    "\n",
    "    # Add a subplot for each desired classification\n",
    "    ax2 = axs[i // 2, i % 2]\n",
    "\n",
    "    # plot the background map\n",
    "    inoutter.boundary.plot(color='gray', ax=ax2, linewidth=2)\n",
    "\n",
    "    tube_line['geometry'] = tube_line.geometry.buffer(500)\n",
    "    tube_line.plot(color='gainsboro', ax=ax2, legend=True)\n",
    "    tube_station.plot(color='green', ax=ax2, legend=True)\n",
    "\n",
    "    try:\n",
    "        # Draw edges\n",
    "        nx.draw_networkx_edges(subgraph, pos=node_positions, width=2, edge_color='skyblue', ax=ax2)\n",
    "\n",
    "        # Set the graph title and axis visibility\n",
    "        ax1.set_title(f'Top 10% Edges with Highest Flow (Classification: {desired_classification})')\n",
    "        ax1.axis('off')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred for the classification '{desired_classification}': {e}\")\n",
    "\n",
    "# Adjust the layout to avoid overlapping plots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
